# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /datamodule: coco.yaml
  - override /model: clip.yaml
  - override /callbacks: default.yaml
  - override /logger: null
  - override /trainer: default.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

# name of the run determines folder name in logs
name: "clip"

seed: 12345

trainer:
  max_epochs: 5

model:
  embed_dim: 512
  transformer_embed_dim: 768
  max_len: 32 # Maximum length of text
  text_model: "distilbert-base-multilingual-cased"
#   net:
#     embed_dim: 1024
#     image_resolution: 448
#     vision_layers: [3, 15, 36, 10]
#     vision_width: 512
#     vision_patch_size: 0
#     context_length: 77
#     vocab_size: 49408
#     transformer_width: 1024
#     transformer_heads: 16
#     transformer_layers: 12

datamodule:
  batch_size: 64
  train_val_test_split: [0.8, 0.1, 0.1]
  num_workers: 4
  pin_memory: True

logger:
  wandb:
    tags: ["clip", "${name}"]

# ckpt_path: "/workspace/jupyter_notebooks/few-shot-cv/pretrained/"